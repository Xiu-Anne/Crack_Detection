{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG19_Crack_Detection&Localization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b84940cbbefb4d788781fe5ec4996419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_21d024bf2c7d4d8ea49285882410ce6a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69dd970f21cf450ca8b3c40ba1fbce4b",
              "IPY_MODEL_4496256dafc14b619968531aef71af13"
            ]
          }
        },
        "21d024bf2c7d4d8ea49285882410ce6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69dd970f21cf450ca8b3c40ba1fbce4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_43fef5efa3d0423b9a27a70d42696fc0",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6573ac7812ea4fea981da242cc200962"
          }
        },
        "4496256dafc14b619968531aef71af13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fef007c865234dd6857e8cdfc7682eac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:15&lt;00:00, 36.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74dfda9a439043ab8e4d2b45bd08e290"
          }
        },
        "43fef5efa3d0423b9a27a70d42696fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6573ac7812ea4fea981da242cc200962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fef007c865234dd6857e8cdfc7682eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74dfda9a439043ab8e4d2b45bd08e290": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4xafRJkxMLG"
      },
      "source": [
        "#https://medium.com/@stepanulyanin/implementing-grad-cam-in-pytorch-ea0937c31e82\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "from torchvision.models import vgg19\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import glob\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06mNbLkod_ZT",
        "outputId": "11af1afa-583a-47f3-e266-4b72d82e2266"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKSDXAD8eCBD",
        "outputId": "f352c89a-02ba-4001-e936-dfe921eaccd3"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Machine_Learning/Crack_Detection') \n",
        "!pwd\n",
        "%ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Machine_Learning/Crack_Detection\n",
            " Autoencoders_Conv2d.ipynb   map.jpg\n",
            " \u001b[0m\u001b[01;34mdata\u001b[0m/                       Pos_00045.tif\n",
            " \u001b[01;34mdata_2\u001b[0m/                    'VGG19_Crack_Detection&Localization.ipynb'\n",
            " \u001b[01;34mGAN\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aal2ByvgdFx2",
        "outputId": "3eb277bd-fbd1-40d3-e576-389d8c40e08f"
      },
      "source": [
        "#https://medium.com/analytics-vidhya/creating-a-custom-dataset-and-dataloader-in-pytorch-76f210a1df5d\n",
        "from skimage.color import gray2rgb\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.imgs_path = \"data_2/\"#\"Crack_Detection/\"\n",
        "        file_list = glob.glob(self.imgs_path + \"*\")\n",
        "        print(file_list)\n",
        "        self.data = []\n",
        "        for class_path in file_list:\n",
        "            class_name = class_path.split(\"/\")[-1]\n",
        "            for img_path in glob.glob(class_path + \"/*.tif\"):#tif\n",
        "                self.data.append([img_path, class_name])\n",
        "        print(len(self.data), self.data[:10])\n",
        "        self.class_map = {\"Negative\" : 0, \"Positive\": 1}\n",
        "        self.img_dim = (224, 224)   \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, class_name = self.data[idx]\n",
        "        img = cv2.imread(img_path)\n",
        "        # converting the type of pixel to float 32\n",
        "        #img = img.astype('float32')\n",
        "        # normalizing the pixel values\n",
        "        #img /= 255.0\n",
        "        #\n",
        "        img = cv2.resize(img, self.img_dim)\n",
        "        class_id = self.class_map[class_name]\n",
        "        img_tensor = torch.from_numpy(gray2rgb(img))\n",
        "        img_tensor = img_tensor.permute(2, 0, 1)\n",
        "        class_id = torch.tensor([class_id])\n",
        "        #return img_tensor, class_id\n",
        "        return img_tensor.float(), class_id.float()\n",
        "\n",
        "dataset = CustomDataset()\n",
        "batch_size=64\n",
        "\n",
        "trainloader = DataLoader(dataset, batch_size, shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data_2/Positive', 'data_2/Negative']\n",
            "384 [['data_2/Positive/Pos_00045.tif', 'Positive'], ['data_2/Positive/Pos_00002.tif', 'Positive'], ['data_2/Positive/Pos_00049.tif', 'Positive'], ['data_2/Positive/Pos_00020.tif', 'Positive'], ['data_2/Positive/Pos_00017.tif', 'Positive'], ['data_2/Positive/Pos_00001.tif', 'Positive'], ['data_2/Positive/Pos_00024.tif', 'Positive'], ['data_2/Positive/Pos_00018.tif', 'Positive'], ['data_2/Positive/Pos_00041.tif', 'Positive'], ['data_2/Positive/Pos_00012.tif', 'Positive']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO5pOKLTxP2A"
      },
      "source": [
        "class VGG(nn.ModuleList):\n",
        "    def __init__(self):\n",
        "        super(VGG, self).__init__()\n",
        "        #self.bs = batch_size\n",
        "        \n",
        "        # get the pretrained VGG19 network\n",
        "        self.vgg = vgg19(pretrained=True)\n",
        "        \n",
        "        # disect the network to access its last convolutional layer\n",
        "        self.features_conv = self.vgg.features[:36]\n",
        "        \n",
        "        # get the max pool of the features stem\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "        \n",
        "        # get the classifier of the vgg19\n",
        "        self.before_classifier = nn.Sequential(nn.Linear(in_features=7*7*512, out_features=1000), nn.ReLU(True), nn.Dropout(0.5), nn.Linear(in_features=1000, out_features=2)) #, nn.Sigmoid()#self.vgg.classifier\n",
        "        self.classifier = nn.Sequential(nn.Linear(in_features=2, out_features=1), nn.Sigmoid()) ##self.vgg.classifier\n",
        "        \n",
        "        # placeholder for the gradients\n",
        "        self.gradients = None\n",
        "    \n",
        "    # hook for the gradients of the activations\n",
        "    def activations_hook(self, grad):\n",
        "        self.gradients = grad\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features_conv(x)\n",
        "        \n",
        "        # register the hook\n",
        "        h = x.register_hook(self.activations_hook)\n",
        "        \n",
        "        # apply the remaining pooling\n",
        "        x = self.max_pool(x)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x1 = self.before_classifier(x)\n",
        "        x2 = self.classifier(x1)\n",
        "        return x1,x2\n",
        "    \n",
        "    # method for the gradient extraction\n",
        "    def get_activations_gradient(self):\n",
        "        return self.gradients\n",
        "    \n",
        "    # method for the activation exctraction\n",
        "    def get_activations(self, x):\n",
        "       return self.features_conv(x)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b84940cbbefb4d788781fe5ec4996419",
            "21d024bf2c7d4d8ea49285882410ce6a",
            "69dd970f21cf450ca8b3c40ba1fbce4b",
            "4496256dafc14b619968531aef71af13",
            "43fef5efa3d0423b9a27a70d42696fc0",
            "6573ac7812ea4fea981da242cc200962",
            "fef007c865234dd6857e8cdfc7682eac",
            "74dfda9a439043ab8e4d2b45bd08e290"
          ]
        },
        "id": "I3Ynpf34gUrp",
        "outputId": "8bb41259-226f-4365-c71b-0a0ced1c3253"
      },
      "source": [
        "#model.compile(optimizer= Adam(lr=0.0001), loss = \"BinaryCrossentropy\", metrics = ['acc'])\n",
        "\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = 'cuda:0'\n",
        "    else:\n",
        "        device = 'cpu'\n",
        "    return device\n",
        "\n",
        "device = get_device()\n",
        "print(device)\n",
        "\n",
        "# initialize the VGG model\n",
        "vgg = VGG()\n",
        "vgg.to(device)\n",
        "print(vgg)\n",
        "from torchsummary import summary\n",
        "summary(vgg,(3,224,224))\n",
        "\n",
        "#Loss function\n",
        "criterion = torch.nn.BCELoss()#BCEWithLogitsLoss()#\n",
        "\n",
        "#Optimizer\n",
        "optimizer = torch.optim.SGD(vgg.parameters(), lr=0.0001, momentum=0.9)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b84940cbbefb4d788781fe5ec4996419",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=574673361.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "VGG(\n",
            "  (vgg): VGG(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (6): ReLU(inplace=True)\n",
            "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (13): ReLU(inplace=True)\n",
            "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (15): ReLU(inplace=True)\n",
            "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (17): ReLU(inplace=True)\n",
            "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (20): ReLU(inplace=True)\n",
            "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (22): ReLU(inplace=True)\n",
            "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (24): ReLU(inplace=True)\n",
            "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (26): ReLU(inplace=True)\n",
            "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (29): ReLU(inplace=True)\n",
            "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (31): ReLU(inplace=True)\n",
            "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (33): ReLU(inplace=True)\n",
            "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (35): ReLU(inplace=True)\n",
            "      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "    (classifier): Sequential(\n",
            "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): Dropout(p=0.5, inplace=False)\n",
            "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (features_conv): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): ReLU(inplace=True)\n",
            "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): ReLU(inplace=True)\n",
            "  )\n",
            "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (before_classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=1000, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=1000, out_features=2, bias=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=1, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "            Conv2d-2         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-3         [-1, 64, 224, 224]               0\n",
            "              ReLU-4         [-1, 64, 224, 224]               0\n",
            "            Conv2d-5         [-1, 64, 224, 224]          36,928\n",
            "            Conv2d-6         [-1, 64, 224, 224]          36,928\n",
            "              ReLU-7         [-1, 64, 224, 224]               0\n",
            "              ReLU-8         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-9         [-1, 64, 112, 112]               0\n",
            "        MaxPool2d-10         [-1, 64, 112, 112]               0\n",
            "           Conv2d-11        [-1, 128, 112, 112]          73,856\n",
            "           Conv2d-12        [-1, 128, 112, 112]          73,856\n",
            "             ReLU-13        [-1, 128, 112, 112]               0\n",
            "             ReLU-14        [-1, 128, 112, 112]               0\n",
            "           Conv2d-15        [-1, 128, 112, 112]         147,584\n",
            "           Conv2d-16        [-1, 128, 112, 112]         147,584\n",
            "             ReLU-17        [-1, 128, 112, 112]               0\n",
            "             ReLU-18        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-19          [-1, 128, 56, 56]               0\n",
            "        MaxPool2d-20          [-1, 128, 56, 56]               0\n",
            "           Conv2d-21          [-1, 256, 56, 56]         295,168\n",
            "           Conv2d-22          [-1, 256, 56, 56]         295,168\n",
            "             ReLU-23          [-1, 256, 56, 56]               0\n",
            "             ReLU-24          [-1, 256, 56, 56]               0\n",
            "           Conv2d-25          [-1, 256, 56, 56]         590,080\n",
            "           Conv2d-26          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-27          [-1, 256, 56, 56]               0\n",
            "             ReLU-28          [-1, 256, 56, 56]               0\n",
            "           Conv2d-29          [-1, 256, 56, 56]         590,080\n",
            "           Conv2d-30          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-31          [-1, 256, 56, 56]               0\n",
            "             ReLU-32          [-1, 256, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]         590,080\n",
            "           Conv2d-34          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "             ReLU-36          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-37          [-1, 256, 28, 28]               0\n",
            "        MaxPool2d-38          [-1, 256, 28, 28]               0\n",
            "           Conv2d-39          [-1, 512, 28, 28]       1,180,160\n",
            "           Conv2d-40          [-1, 512, 28, 28]       1,180,160\n",
            "             ReLU-41          [-1, 512, 28, 28]               0\n",
            "             ReLU-42          [-1, 512, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]       2,359,808\n",
            "           Conv2d-44          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-45          [-1, 512, 28, 28]               0\n",
            "             ReLU-46          [-1, 512, 28, 28]               0\n",
            "           Conv2d-47          [-1, 512, 28, 28]       2,359,808\n",
            "           Conv2d-48          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-49          [-1, 512, 28, 28]               0\n",
            "             ReLU-50          [-1, 512, 28, 28]               0\n",
            "           Conv2d-51          [-1, 512, 28, 28]       2,359,808\n",
            "           Conv2d-52          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-53          [-1, 512, 28, 28]               0\n",
            "             ReLU-54          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-55          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-56          [-1, 512, 14, 14]               0\n",
            "           Conv2d-57          [-1, 512, 14, 14]       2,359,808\n",
            "           Conv2d-58          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-59          [-1, 512, 14, 14]               0\n",
            "             ReLU-60          [-1, 512, 14, 14]               0\n",
            "           Conv2d-61          [-1, 512, 14, 14]       2,359,808\n",
            "           Conv2d-62          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-63          [-1, 512, 14, 14]               0\n",
            "             ReLU-64          [-1, 512, 14, 14]               0\n",
            "           Conv2d-65          [-1, 512, 14, 14]       2,359,808\n",
            "           Conv2d-66          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-67          [-1, 512, 14, 14]               0\n",
            "             ReLU-68          [-1, 512, 14, 14]               0\n",
            "           Conv2d-69          [-1, 512, 14, 14]       2,359,808\n",
            "           Conv2d-70          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-71          [-1, 512, 14, 14]               0\n",
            "             ReLU-72          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-73            [-1, 512, 7, 7]               0\n",
            "           Linear-74                 [-1, 1000]      25,089,000\n",
            "             ReLU-75                 [-1, 1000]               0\n",
            "          Dropout-76                 [-1, 1000]               0\n",
            "           Linear-77                    [-1, 2]           2,002\n",
            "           Linear-78                    [-1, 1]               3\n",
            "          Sigmoid-79                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 65,139,773\n",
            "Trainable params: 65,139,773\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 476.43\n",
            "Params size (MB): 248.49\n",
            "Estimated Total Size (MB): 725.50\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxbXmt2h90R_"
      },
      "source": [
        "#Optimizer\n",
        "optimizer = torch.optim.SGD(vgg.parameters(), lr=0.00005, momentum=0.9)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGMkX2EGh5UC",
        "outputId": "0526d3b6-8cf8-4350-9b10-830c27a2195e"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "Tensor = torch.cuda.FloatTensor if device == 'cuda:0' else torch.FloatTensor\n",
        "\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        #inputs, labels = Variable(inputs), Variable(labels)\n",
        "        inputs.to(device)\n",
        "        labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        _,output = vgg(inputs.type(Tensor))\n",
        "        #outputs = torch.tensor(output.argmax(dim=1), dtype = torch.float)\n",
        "\n",
        "        loss = criterion(output, labels.type(Tensor))\n",
        "        #loss.requres_grad = True\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2 == 1:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.6f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,     2] loss: 0.000017\n",
            "[1,     4] loss: 0.000020\n",
            "[1,     6] loss: 0.000024\n",
            "[2,     2] loss: 0.000025\n",
            "[2,     4] loss: 0.000016\n",
            "[2,     6] loss: 0.000021\n",
            "[3,     2] loss: 0.000017\n",
            "[3,     4] loss: 0.000022\n",
            "[3,     6] loss: 0.000022\n",
            "[4,     2] loss: 0.000026\n",
            "[4,     4] loss: 0.000017\n",
            "[4,     6] loss: 0.000019\n",
            "[5,     2] loss: 0.000020\n",
            "[5,     4] loss: 0.000022\n",
            "[5,     6] loss: 0.000019\n",
            "[6,     2] loss: 0.000021\n",
            "[6,     4] loss: 0.000016\n",
            "[6,     6] loss: 0.000025\n",
            "[7,     2] loss: 0.000020\n",
            "[7,     4] loss: 0.000021\n",
            "[7,     6] loss: 0.000020\n",
            "[8,     2] loss: 0.000018\n",
            "[8,     4] loss: 0.000021\n",
            "[8,     6] loss: 0.000022\n",
            "[9,     2] loss: 0.000019\n",
            "[9,     4] loss: 0.000021\n",
            "[9,     6] loss: 0.000021\n",
            "[10,     2] loss: 0.000023\n",
            "[10,     4] loss: 0.000016\n",
            "[10,     6] loss: 0.000021\n",
            "[11,     2] loss: 0.000018\n",
            "[11,     4] loss: 0.000024\n",
            "[11,     6] loss: 0.000019\n",
            "[12,     2] loss: 0.000018\n",
            "[12,     4] loss: 0.000025\n",
            "[12,     6] loss: 0.000018\n",
            "[13,     2] loss: 0.000023\n",
            "[13,     4] loss: 0.000023\n",
            "[13,     6] loss: 0.000015\n",
            "[14,     2] loss: 0.000023\n",
            "[14,     4] loss: 0.000018\n",
            "[14,     6] loss: 0.000019\n",
            "[15,     2] loss: 0.000020\n",
            "[15,     4] loss: 0.000020\n",
            "[15,     6] loss: 0.000021\n",
            "[16,     2] loss: 0.000022\n",
            "[16,     4] loss: 0.000018\n",
            "[16,     6] loss: 0.000021\n",
            "[17,     2] loss: 0.000020\n",
            "[17,     4] loss: 0.000022\n",
            "[17,     6] loss: 0.000018\n",
            "[18,     2] loss: 0.000022\n",
            "[18,     4] loss: 0.000021\n",
            "[18,     6] loss: 0.000017\n",
            "[19,     2] loss: 0.000020\n",
            "[19,     4] loss: 0.000019\n",
            "[19,     6] loss: 0.000021\n",
            "[20,     2] loss: 0.000018\n",
            "[20,     4] loss: 0.000026\n",
            "[20,     6] loss: 0.000016\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jys7B3xylJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd902f1-676c-41c7-c111-a996c4ae5043"
      },
      "source": [
        "# set the evaluation mode\n",
        "vgg.eval()\n",
        "\n",
        "# get the image from the dataloader\n",
        "#img, _ = next(iter(trainloader))\n",
        "#pred = vgg(img)\n",
        "\n",
        "img = cv2.imread(\"Pos_00100.tif\")\n",
        "img = cv2.resize(img, (224, 224) )\n",
        "img_tensor = torch.from_numpy(gray2rgb(img))\n",
        "#print(img_tensor.shape[0], img_tensor.shape[1], img_tensor.shape[2])\n",
        "img_tensor = img_tensor.permute(2, 0, 1)\n",
        "#print(img_tensor.shape[0], img_tensor.shape[1], img_tensor.shape[2])\n",
        "img_tensor = img_tensor.unsqueeze(0)\n",
        "#print(img_tensor.shape[0], img_tensor.shape[1], img_tensor.shape[2], img_tensor.shape[3])\n",
        "img_tensor.to(device)\n",
        "\n",
        "# get the most likely prediction of the model\n",
        "pred1, pred2 = vgg(img_tensor.type(torch.cuda.FloatTensor))\n",
        "print(pred1, pred2)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[20.2453,  7.9274]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[1.0000]], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SO4kX5eyoOW"
      },
      "source": [
        "# get the gradient of the output with respect to the parameters of the model\n",
        "#Active = torch.nn.Sequential(*list(vgg.children())[:-1])\n",
        "#final_layer = list(vgg.children())[-1]\n",
        "\n",
        "pred1[:, 1].backward()\n",
        "\n",
        "# pull the gradients out of the model\n",
        "gradients = vgg.get_activations_gradient()\n",
        "\n",
        "# pool the gradients across the channels\n",
        "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
        "\n",
        "# get the activations of the last convolutional layer\n",
        "activations = vgg.get_activations(img_tensor.type(torch.cuda.FloatTensor)).detach()\n",
        "\n",
        "# weight the channels by corresponding gradients\n",
        "for i in range(512):\n",
        "    activations[:, i, :, :] *= pooled_gradients[i]\n",
        "    \n",
        "# average the channels of the activations\n",
        "heatmap = torch.mean(activations, dim=1).squeeze()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "ZrmMHHQXdlRV",
        "outputId": "1d93569c-ba3d-482f-f2ae-b4a973aed943"
      },
      "source": [
        "# relu on top of the heatmap\n",
        "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
        "heatmap = np.maximum(heatmap.cpu(), 0)\n",
        "\n",
        "# normalize the heatmap\n",
        "heatmap /= torch.max(heatmap)\n",
        "\n",
        "# draw the heatmap\n",
        "plt.matshow(heatmap.squeeze())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2dd1e41a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFLh4tSTy-GQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e4a780-eeb1-4622-821a-c5a3ca996be7"
      },
      "source": [
        "print(img_tensor.shape[2], img_tensor.shape[3])\n",
        "heatmap = cv2.resize(np.float32(heatmap), (img_tensor.shape[2], img_tensor.shape[3]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = heatmap * 0.3 + img\n",
        "cv2.imwrite('./map.jpg', superimposed_img)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "224 224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLOp-Fa1sVBB"
      },
      "source": [
        "for epoch in range(0):  # loop over the dataset multiple times\n",
        "\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for data in trainloader:\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        \n",
        "        inputs.to(device)\n",
        "        labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = vgg(inputs.type(torch.cuda.FloatTensor))\n",
        "\n",
        "        loss = criterion(outputs, (labels.type(torch.cuda.FloatTensor)))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()*inputs.size(0)\n",
        "          \n",
        "    train_loss = train_loss/len(trainloader)\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}