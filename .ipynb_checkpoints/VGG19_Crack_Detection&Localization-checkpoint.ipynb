{
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VGG19_Crack_Detection&Localization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "name": "",
  "signature": "sha256:7dec9047c8073b8433b627b37764ff46cf08efb4a72b2c9c8aac6bd1934ae2a0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#https://medium.com/@stepanulyanin/implementing-grad-cam-in-pytorch-ea0937c31e82\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from torch.utils import data\n",
      "from torchvision.models import vgg19\n",
      "from torchvision import transforms\n",
      "from torchvision import datasets\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "import glob\n",
      "import cv2\n",
      "from torch.utils.data import Dataset, DataLoader"
     ],
     "language": "python",
     "metadata": {
      "id": "e4xafRJkxMLG"
     },
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from google.colab import drive\n",
      "drive.mount('/content/drive')"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/"
      },
      "id": "06mNbLkod_ZT",
      "outputId": "54a10570-9f26-460d-b13a-a555b135b600"
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "os.chdir('/content/drive/MyDrive/Machine_Learning/Crack_Detection') \n",
      "!pwd\n",
      "%ls"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/"
      },
      "id": "sKSDXAD8eCBD",
      "outputId": "95743d1e-e414-481b-94d7-c4a7b344c461"
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/content/drive/MyDrive/Machine_Learning/Crack_Detection\n",
        " Autoencoders_Conv2d.ipynb          map.jpg\n",
        " \u001b[0m\u001b[01;34mdata\u001b[0m/                              Neg_01249.tif\n",
        " \u001b[01;34mdata_2\u001b[0m/                            Pos_00045.tif\n",
        " \u001b[01;34mGAN\u001b[0m/                               Pos_00100.tif\n",
        " jx_vit_base_p16_224-80ecf9dd.pth  'VGG19_Crack_Detection&Localization.ipynb'\n",
        " map_1.jpg                          ViTransformers.ipynb\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#https://medium.com/analytics-vidhya/creating-a-custom-dataset-and-dataloader-in-pytorch-76f210a1df5d\n",
      "from skimage.color import gray2rgb\n",
      "class CustomDataset(Dataset):\n",
      "    def __init__(self):\n",
      "        self.imgs_path = \"data_2/\"\n",
      "        file_list = glob.glob(self.imgs_path + \"*\")\n",
      "        print(file_list)\n",
      "        self.data = []\n",
      "        for class_path in file_list:\n",
      "            class_name = class_path.split(\"/\")[-1]\n",
      "            for img_path in glob.glob(class_path + \"/*.tif\"):#tif\n",
      "                self.data.append([img_path, class_name])\n",
      "        print(len(self.data), self.data[:10])\n",
      "        self.class_map = {\"Negative\" : 0, \"Positive\": 1}\n",
      "        self.img_dim = (224, 224)   \n",
      "\n",
      "    def __len__(self):\n",
      "        return len(self.data)\n",
      "\n",
      "    def __getitem__(self, idx):\n",
      "        img_path, class_name = self.data[idx]\n",
      "        img = cv2.imread(img_path)\n",
      "        #\n",
      "        img = cv2.resize(img, self.img_dim)\n",
      "        class_id = self.class_map[class_name]\n",
      "        img_tensor = torch.from_numpy(gray2rgb(img))\n",
      "        img_tensor = img_tensor.permute(2, 0, 1)\n",
      "        class_id = torch.tensor([class_id])\n",
      "        #return img_tensor, class_id\n",
      "        return img_tensor.float(), class_id#.float()\n",
      "\n",
      "dataset = CustomDataset()\n",
      "batch_size=64\n",
      "\n",
      "trainloader = DataLoader(dataset, batch_size, shuffle=True)"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/"
      },
      "id": "Aal2ByvgdFx2",
      "outputId": "01f6ffae-c5ad-48dc-c7c3-5ad64840b0d7"
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['data_2/Positive', 'data_2/Negative']\n",
        "384 [['data_2/Positive/Pos_00045.tif', 'Positive'], ['data_2/Positive/Pos_00002.tif', 'Positive'], ['data_2/Positive/Pos_00049.tif', 'Positive'], ['data_2/Positive/Pos_00020.tif', 'Positive'], ['data_2/Positive/Pos_00017.tif', 'Positive'], ['data_2/Positive/Pos_00001.tif', 'Positive'], ['data_2/Positive/Pos_00024.tif', 'Positive'], ['data_2/Positive/Pos_00018.tif', 'Positive'], ['data_2/Positive/Pos_00041.tif', 'Positive'], ['data_2/Positive/Pos_00012.tif', 'Positive']]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class VGG(nn.ModuleList):\n",
      "    def __init__(self):\n",
      "        super(VGG, self).__init__()\n",
      "        #self.bs = batch_size\n",
      "        \n",
      "        # get the pretrained VGG19 network\n",
      "        self.vgg = vgg19(pretrained=True)\n",
      "        \n",
      "        # disect the network to access its last convolutional layer\n",
      "        self.features_conv = self.vgg.features[:36]\n",
      "        \n",
      "        # get the max pool of the features stem\n",
      "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        \n",
      "        # get the classifier of the vgg19\n",
      "        self.classifier = nn.Sequential(nn.Linear(in_features=7*7*512, out_features=1000), nn.ReLU(True), nn.Dropout(0.5), nn.Linear(in_features=1000, out_features=2)) #, nn.Sigmoid()#self.vgg.classifier\n",
      "        \n",
      "        # placeholder for the gradients\n",
      "        self.gradients = None\n",
      "    \n",
      "    # hook for the gradients of the activations\n",
      "    def activations_hook(self, grad):\n",
      "        self.gradients = grad\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = self.features_conv(x)\n",
      "        \n",
      "        # register the hook\n",
      "        h = x.register_hook(self.activations_hook)\n",
      "        \n",
      "        # apply the remaining pooling\n",
      "        x = self.max_pool(x)\n",
      "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
      "        x = self.classifier(x)\n",
      "        return x\n",
      "    \n",
      "    # method for the gradient extraction\n",
      "    def get_activations_gradient(self):\n",
      "        return self.gradients\n",
      "    \n",
      "    # method for the activation exctraction\n",
      "    def get_activations(self, x):\n",
      "       return self.features_conv(x)"
     ],
     "language": "python",
     "metadata": {
      "id": "DO5pOKLTxP2A"
     },
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def get_device():\n",
      "    if torch.cuda.is_available():\n",
      "        device = 'cuda:0'\n",
      "    else:\n",
      "        device = 'cpu'\n",
      "    return device\n",
      "\n",
      "device = get_device()\n",
      "print(device)\n",
      "\n",
      "# initialize the VGG model\n",
      "vgg = VGG()\n",
      "vgg.to(device)\n",
      "\n",
      "from torchsummary import summary\n",
      "summary(vgg,(3,224,224))\n",
      "\n",
      "#Loss function\n",
      "criterion = torch.nn.BCEWithLogitsLoss()#BCELoss()#\n",
      "\n",
      "#Optimizer\n",
      "optimizer = torch.optim.Adam(vgg.parameters(), lr=0.0001)"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/"
      },
      "id": "I3Ynpf34gUrp",
      "outputId": "3ca6dd23-cd58-49f3-8181-8b28a94fa9c9"
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cuda:0\n",
        "VGG(\n",
        "  (vgg): VGG(\n",
        "    (features): Sequential(\n",
        "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (1): ReLU(inplace=True)\n",
        "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (3): ReLU(inplace=True)\n",
        "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (6): ReLU(inplace=True)\n",
        "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (8): ReLU(inplace=True)\n",
        "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (11): ReLU(inplace=True)\n",
        "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (13): ReLU(inplace=True)\n",
        "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (15): ReLU(inplace=True)\n",
        "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (17): ReLU(inplace=True)\n",
        "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (20): ReLU(inplace=True)\n",
        "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (22): ReLU(inplace=True)\n",
        "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (24): ReLU(inplace=True)\n",
        "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (26): ReLU(inplace=True)\n",
        "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (29): ReLU(inplace=True)\n",
        "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (31): ReLU(inplace=True)\n",
        "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (33): ReLU(inplace=True)\n",
        "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "      (35): ReLU(inplace=True)\n",
        "      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    )\n",
        "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
        "    (classifier): Sequential(\n",
        "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
        "      (1): ReLU(inplace=True)\n",
        "      (2): Dropout(p=0.5, inplace=False)\n",
        "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
        "      (4): ReLU(inplace=True)\n",
        "      (5): Dropout(p=0.5, inplace=False)\n",
        "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
        "    )\n",
        "  )\n",
        "  (features_conv): Sequential(\n",
        "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (1): ReLU(inplace=True)\n",
        "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (3): ReLU(inplace=True)\n",
        "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (6): ReLU(inplace=True)\n",
        "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (8): ReLU(inplace=True)\n",
        "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (11): ReLU(inplace=True)\n",
        "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (13): ReLU(inplace=True)\n",
        "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (15): ReLU(inplace=True)\n",
        "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (17): ReLU(inplace=True)\n",
        "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (20): ReLU(inplace=True)\n",
        "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (22): ReLU(inplace=True)\n",
        "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (24): ReLU(inplace=True)\n",
        "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (26): ReLU(inplace=True)\n",
        "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (29): ReLU(inplace=True)\n",
        "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (31): ReLU(inplace=True)\n",
        "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (33): ReLU(inplace=True)\n",
        "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    (35): ReLU(inplace=True)\n",
        "  )\n",
        "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "  (classifier): Sequential(\n",
        "    (0): Linear(in_features=25088, out_features=1000, bias=True)\n",
        "    (1): ReLU(inplace=True)\n",
        "    (2): Dropout(p=0.5, inplace=False)\n",
        "    (3): Linear(in_features=1000, out_features=2, bias=True)\n",
        "  )\n",
        ")\n",
        "----------------------------------------------------------------\n",
        "        Layer (type)               Output Shape         Param #\n",
        "================================================================\n",
        "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
        "            Conv2d-2         [-1, 64, 224, 224]           1,792\n",
        "              ReLU-3         [-1, 64, 224, 224]               0\n",
        "              ReLU-4         [-1, 64, 224, 224]               0\n",
        "            Conv2d-5         [-1, 64, 224, 224]          36,928\n",
        "            Conv2d-6         [-1, 64, 224, 224]          36,928\n",
        "              ReLU-7         [-1, 64, 224, 224]               0\n",
        "              ReLU-8         [-1, 64, 224, 224]               0\n",
        "         MaxPool2d-9         [-1, 64, 112, 112]               0\n",
        "        MaxPool2d-10         [-1, 64, 112, 112]               0\n",
        "           Conv2d-11        [-1, 128, 112, 112]          73,856\n",
        "           Conv2d-12        [-1, 128, 112, 112]          73,856\n",
        "             ReLU-13        [-1, 128, 112, 112]               0\n",
        "             ReLU-14        [-1, 128, 112, 112]               0\n",
        "           Conv2d-15        [-1, 128, 112, 112]         147,584\n",
        "           Conv2d-16        [-1, 128, 112, 112]         147,584\n",
        "             ReLU-17        [-1, 128, 112, 112]               0\n",
        "             ReLU-18        [-1, 128, 112, 112]               0\n",
        "        MaxPool2d-19          [-1, 128, 56, 56]               0\n",
        "        MaxPool2d-20          [-1, 128, 56, 56]               0\n",
        "           Conv2d-21          [-1, 256, 56, 56]         295,168\n",
        "           Conv2d-22          [-1, 256, 56, 56]         295,168\n",
        "             ReLU-23          [-1, 256, 56, 56]               0\n",
        "             ReLU-24          [-1, 256, 56, 56]               0\n",
        "           Conv2d-25          [-1, 256, 56, 56]         590,080\n",
        "           Conv2d-26          [-1, 256, 56, 56]         590,080\n",
        "             ReLU-27          [-1, 256, 56, 56]               0\n",
        "             ReLU-28          [-1, 256, 56, 56]               0\n",
        "           Conv2d-29          [-1, 256, 56, 56]         590,080\n",
        "           Conv2d-30          [-1, 256, 56, 56]         590,080\n",
        "             ReLU-31          [-1, 256, 56, 56]               0\n",
        "             ReLU-32          [-1, 256, 56, 56]               0\n",
        "           Conv2d-33          [-1, 256, 56, 56]         590,080\n",
        "           Conv2d-34          [-1, 256, 56, 56]         590,080\n",
        "             ReLU-35          [-1, 256, 56, 56]               0\n",
        "             ReLU-36          [-1, 256, 56, 56]               0\n",
        "        MaxPool2d-37          [-1, 256, 28, 28]               0\n",
        "        MaxPool2d-38          [-1, 256, 28, 28]               0\n",
        "           Conv2d-39          [-1, 512, 28, 28]       1,180,160\n",
        "           Conv2d-40          [-1, 512, 28, 28]       1,180,160\n",
        "             ReLU-41          [-1, 512, 28, 28]               0\n",
        "             ReLU-42          [-1, 512, 28, 28]               0\n",
        "           Conv2d-43          [-1, 512, 28, 28]       2,359,808\n",
        "           Conv2d-44          [-1, 512, 28, 28]       2,359,808\n",
        "             ReLU-45          [-1, 512, 28, 28]               0\n",
        "             ReLU-46          [-1, 512, 28, 28]               0\n",
        "           Conv2d-47          [-1, 512, 28, 28]       2,359,808\n",
        "           Conv2d-48          [-1, 512, 28, 28]       2,359,808\n",
        "             ReLU-49          [-1, 512, 28, 28]               0\n",
        "             ReLU-50          [-1, 512, 28, 28]               0\n",
        "           Conv2d-51          [-1, 512, 28, 28]       2,359,808\n",
        "           Conv2d-52          [-1, 512, 28, 28]       2,359,808\n",
        "             ReLU-53          [-1, 512, 28, 28]               0\n",
        "             ReLU-54          [-1, 512, 28, 28]               0\n",
        "        MaxPool2d-55          [-1, 512, 14, 14]               0\n",
        "        MaxPool2d-56          [-1, 512, 14, 14]               0\n",
        "           Conv2d-57          [-1, 512, 14, 14]       2,359,808\n",
        "           Conv2d-58          [-1, 512, 14, 14]       2,359,808\n",
        "             ReLU-59          [-1, 512, 14, 14]               0\n",
        "             ReLU-60          [-1, 512, 14, 14]               0\n",
        "           Conv2d-61          [-1, 512, 14, 14]       2,359,808\n",
        "           Conv2d-62          [-1, 512, 14, 14]       2,359,808\n",
        "             ReLU-63          [-1, 512, 14, 14]               0\n",
        "             ReLU-64          [-1, 512, 14, 14]               0\n",
        "           Conv2d-65          [-1, 512, 14, 14]       2,359,808\n",
        "           Conv2d-66          [-1, 512, 14, 14]       2,359,808\n",
        "             ReLU-67          [-1, 512, 14, 14]               0\n",
        "             ReLU-68          [-1, 512, 14, 14]               0\n",
        "           Conv2d-69          [-1, 512, 14, 14]       2,359,808\n",
        "           Conv2d-70          [-1, 512, 14, 14]       2,359,808\n",
        "             ReLU-71          [-1, 512, 14, 14]               0\n",
        "             ReLU-72          [-1, 512, 14, 14]               0\n",
        "        MaxPool2d-73            [-1, 512, 7, 7]               0\n",
        "           Linear-74                 [-1, 1000]      25,089,000\n",
        "             ReLU-75                 [-1, 1000]               0\n",
        "          Dropout-76                 [-1, 1000]               0\n",
        "           Linear-77                    [-1, 2]           2,002\n",
        "================================================================\n",
        "Total params: 65,139,770\n",
        "Trainable params: 65,139,770\n",
        "Non-trainable params: 0\n",
        "----------------------------------------------------------------\n",
        "Input size (MB): 0.57\n",
        "Forward/backward pass size (MB): 476.43\n",
        "Params size (MB): 248.49\n",
        "Estimated Total Size (MB): 725.50\n",
        "----------------------------------------------------------------\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
        "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def indices_to_one_hot(data, nb_classes):\n",
      "    \"\"\"Convert an iterable of indices to one-hot encoded labels.\"\"\"\n",
      "    targets = np.array(data).reshape(-1)\n",
      "    return np.eye(nb_classes)[targets]"
     ],
     "language": "python",
     "metadata": {
      "id": "F8S_d4Rjy4Wl"
     },
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from torch.autograd import Variable\n",
      "Tensor = torch.cuda.FloatTensor if device == 'cuda:0' else torch.FloatTensor\n",
      "\n",
      "for epoch in range(100):  # loop over the dataset multiple times\n",
      "\n",
      "    running_loss = 0.0\n",
      "\n",
      "    for i, data in enumerate(trainloader, 0):\n",
      "        # get the inputs; data is a list of [inputs, labels]\n",
      "        inputs, labels = data\n",
      "        labels = torch.from_numpy(indices_to_one_hot(labels, 2))\n",
      "        inputs.to(device)\n",
      "        labels.to(device)\n",
      "\n",
      "        # zero the parameter gradients\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        # forward + backward + optimize\n",
      "        output = vgg(inputs.type(Tensor))\n",
      "\n",
      "        loss = criterion(output, labels.type(Tensor))\n",
      "\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "\n",
      "        # print statistics\n",
      "        running_loss += loss.item()\n",
      "        if i % 2 == 1:    # print every 2000 mini-batches\n",
      "            print('[%d, %5d] loss: %.6f' %\n",
      "                  (epoch + 1, i + 1, running_loss / 2))\n",
      "            running_loss = 0.0\n",
      "\n",
      "print('Finished Training')"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/",
       "height": 790
      },
      "id": "aGMkX2EGh5UC",
      "outputId": "462f1d21-e04a-4a95-bee7-0c2b6d5aa0e5"
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1,     2] loss: 0.000000\n",
        "[1,     4] loss: 0.000000\n",
        "[1,     6] loss: 0.000003\n",
        "[2,     2] loss: 0.000003\n",
        "[2,     4] loss: 0.000000\n",
        "[2,     6] loss: 0.000000\n",
        "[3,     2] loss: 0.000001\n",
        "[3,     4] loss: 0.000000\n",
        "[3,     6] loss: 0.000001\n",
        "[4,     2] loss: 0.000000\n",
        "[4,     4] loss: 0.000001\n",
        "[4,     6] loss: 0.000000\n",
        "[5,     2] loss: 0.000002\n",
        "[5,     4] loss: 0.000000\n",
        "[5,     6] loss: 0.000000\n",
        "[6,     2] loss: 0.000000\n",
        "[6,     4] loss: 0.000001\n",
        "[6,     6] loss: 0.000000\n",
        "[7,     2] loss: 0.000000\n",
        "[7,     4] loss: 0.000001\n",
        "[7,     6] loss: 0.000000\n",
        "[8,     2] loss: 0.000000\n",
        "[8,     4] loss: 0.000001\n",
        "[8,     6] loss: 0.000000\n",
        "[9,     2] loss: 0.000000\n",
        "[9,     4] loss: 0.000001\n",
        "[9,     6] loss: 0.000000\n",
        "[10,     2] loss: 0.000000\n",
        "[10,     4] loss: 0.000000\n",
        "[10,     6] loss: 0.000001\n",
        "[11,     2] loss: 0.000001\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "ignored",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-32-74e4f9d3dcf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# print every 2000 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             print('[%d, %5d] loss: %.6f' %\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set the evaluation mode\n",
      "vgg.eval()\n",
      "\n",
      "# get the image from the dataloader\n",
      "#img, _ = next(iter(trainloader))\n",
      "#pred = vgg(img)\n",
      "\n",
      "img = cv2.imread(\"Pos_00045.tif\")\n",
      "#img = cv2.imread(\"Pos_00100.tif\")\n",
      "img = cv2.resize(img, (224, 224) )\n",
      "img_tensor = torch.from_numpy(gray2rgb(img))\n",
      "img_tensor = img_tensor.permute(2, 0, 1)\n",
      "img_tensor = img_tensor.unsqueeze(0)\n",
      "img_tensor.to(device)\n",
      "\n",
      "# get the most likely prediction of the model\n",
      "pred = vgg(img_tensor.type(Tensor))\n",
      "print(pred)"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/"
      },
      "id": "4jys7B3xylJa",
      "outputId": "af0ed298-ac91-43b8-b2ea-b31c34a4f0cb"
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tensor([[-74.1050,  68.2822]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the gradient of the output with respect to the parameters of the model\n",
      "\n",
      "#Active = torch.nn.Sequential(*list(vgg.children())[:-1])\n",
      "#final_layer = list(vgg.children())[-1]\n",
      "\n",
      "pred[:, 1].backward()\n",
      "\n",
      "# pull the gradients out of the model\n",
      "gradients = vgg.get_activations_gradient()\n",
      "\n",
      "# pool the gradients across the channels\n",
      "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
      "\n",
      "# get the activations of the last convolutional layer\n",
      "activations = vgg.get_activations(img_tensor.type(Tensor)).detach()\n",
      "\n",
      "# weight the channels by corresponding gradients\n",
      "for i in range(512):\n",
      "    activations[:, i, :, :] *= pooled_gradients[i]\n",
      "    \n",
      "# average the channels of the activations\n",
      "heatmap = torch.mean(activations, dim=1).squeeze()"
     ],
     "language": "python",
     "metadata": {
      "id": "_SO4kX5eyoOW"
     },
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
      "heatmap = np.maximum(heatmap.cpu(), 0)\n",
      "\n",
      "# normalize the heatmap\n",
      "heatmap /= torch.max(heatmap)\n",
      "\n",
      "# draw the heatmap\n",
      "plt.matshow(heatmap.squeeze())"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/",
       "height": 292
      },
      "id": "ZrmMHHQXdlRV",
      "outputId": "fae9bb53-2c59-462e-c2a7-f0c0c43b339e"
     },
     "outputs": [
      {
       "metadata": {
        "tags": []
       },
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "<matplotlib.image.AxesImage at 0x7efb6aea7c50>"
       ]
      },
      {
       "metadata": {
        "needs_background": "light",
        "tags": []
       },
       "output_type": "display_data",
       "png": "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\n",
       "text": [
        "<Figure size 288x288 with 1 Axes>"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(img_tensor.shape[2], img_tensor.shape[3])\n",
      "heatmap = cv2.resize(np.float32(heatmap), (img_tensor.shape[2], img_tensor.shape[3]))\n",
      "heatmap = np.uint8(255 * heatmap)\n",
      "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
      "superimposed_img = heatmap * 0.3 + img\n",
      "cv2.imwrite('./map.jpg', superimposed_img)"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/"
      },
      "id": "nFLh4tSTy-GQ",
      "outputId": "cee0f8b0-9469-492d-fe9a-239eb40da560"
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "224 224\n"
       ]
      },
      {
       "metadata": {
        "tags": []
       },
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {
      "id": "0577PViFlAni"
     },
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}